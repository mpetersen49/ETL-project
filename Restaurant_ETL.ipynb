{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E - extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in the extract phase of this ETL is to import the needed frameworks to run the script in this jupyter notebook. Here we import pandas, sqlalchemy, numpy, and a config file. The below cell contains all of these imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "from config import username, password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will load the 5 csv files that are located in the \"Resources\" folder of this repo. To do this step we will set each files pathway to its' own variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_file = \"Resources/mcd_menu.csv\"\n",
    "bk_mcd_file = \"Resources/bk_mcd_menu.csv\"\n",
    "starbucks_food_file = \"Resources/starbucks_food.csv\"\n",
    "starbucks_drink_file = \"Resources/starbucks_drink_menu.csv\"\n",
    "subway_file = \"Resources/subway_menu.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use the pandas \".read_csv\" functionality to read each of our csv's into a dataframe. This allows us to prepare for the transform step as we can now see the data of each csv cleanly presented through the power of the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_df = pd.read_csv(mcd_file)\n",
    "bk_mcd_df = pd.read_csv(bk_mcd_file, delimiter=';')\n",
    "starbucks_food_df = pd.read_csv(starbucks_food_file)\n",
    "starbucks_drink_df = pd.read_csv(starbucks_drink_file)\n",
    "subway_df = pd.read_csv(subway_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T - transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 5 data frames created we will first take a quick look using the \".head()\" functionality. Now we can assess the current state of the dataframe and see what information needs to be transformed in order to get the data frames to all be congruent to the ERD diagram versions we had envisioned.\n",
    "\n",
    "This most often included: dropping uneeded rows, renaming rows to be lowercase or fit our naming conventions, adding our \"food_class\" column and assigning the correct number designator for dessert (1) drink (2) or food (3).\n",
    "\n",
    "Finally we would display our fully transformed data frame and move onto the next data frame to repeat the process as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Data Frame Transformation: Subway_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see with the \".head()\" there are a number of columns in this data frame that we do not need. There are also columns that we do need but that do not fit our naming conventions.\n",
    "\n",
    "The \".unique()\" on the column \"Category\" also reveals a category in subways menu that is called \"Extra\" by viewing the whole database we were able to determine that everything which was classified under the \"Extra\" fell most in-line with a dessert classification.\n",
    "\n",
    "We will grab the columns that we want and copy them to a \"transformed\" data frame. Then we will rename the columns of our new data frame so that they are aligned with our desired naming conventions.\n",
    "\n",
    "Next we created a condition in which the category \"Extra\" would recieve the value of 1 signifying it as a dessert. This was accomplished by setting the variables accordingly and using the numpy functionality \"select\"\n",
    "\n",
    "All other rows in this new column \"food_class\" were given the designation of 3 for a food item.\n",
    "\n",
    "The index was set to \"id\" and the transformed data frame can now be displayed in its full glory with one more \".head()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns desired for database\n",
    "subway_transformed = subway_df[[\"Category\", \"Unnamed: 0\", \"Saturated Fat (g)\", \"Calories\"]].copy()\n",
    "\n",
    "# rename columns\n",
    "subway_transformed.rename(columns={\"Category\": \"category\", \n",
    "                                   \"Unnamed: 0\": \"item\",\n",
    "                                   \"Saturated Fat (g)\": \"saturated_fat\",\n",
    "                                   \"Calories\": \"calories\"}, inplace=True)\n",
    "\n",
    "# add \"food_class\" column\n",
    "# recognizing that category == Extra are desserts in the dataset\n",
    "conditions = [(subway_transformed[\"category\"] == \"Extra\")]\n",
    "\n",
    "values = [1]\n",
    "\n",
    "subway_transformed[\"food_class\"] = np.select(conditions, values)\n",
    "\n",
    "subway_transformed[\"food_class\"].replace(0,3, inplace=True)\n",
    "\n",
    "# create \"id\" column\n",
    "subway_transformed[\"id\"] = subway_transformed.index\n",
    "\n",
    "subway_transformed.set_index(\"id\", inplace=True)\n",
    "\n",
    "# display dataframe\n",
    "subway_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Data Frame Transformation: mcd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second data frame transformation went extremely similar to the first. The df was viewed using a \".head()\" so that we could see which columns and other data would need to be transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again grab the name of the columns that fit our needs and save them as a list to a variable called \"mcd_cols\"\n",
    "\n",
    "This is copied into a new data frame and the column names are updated.\n",
    "\n",
    "Things are looking good but we are not there just yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "mcd_cols = [\"Category\", \"Item\", \"Saturated Fat\", \"Calories\"]\n",
    "mcd_transformed= mcd_df[mcd_cols].copy()\n",
    "\n",
    "# Rename the column headers for consistency\n",
    "mcd_transformed = mcd_transformed.rename(columns={\"Category\": \"category\",\n",
    "                                                    \"Item\": \"item\",\n",
    "                                                    \"Saturated Fat\": \"saturated_fat\",\n",
    "                                                    \"Calories\": \"calories\"})\n",
    "\n",
    "mcd_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking another look at the \"category\" column we can see all of the different classes and make decisions on which of our three \"food_class\" numbers should go to each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find full list of categories\n",
    "mcd_transformed['category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we did for the subway example, we assign each category to a conditions variable, which is a list. Then using numpy we can assign our values for the \"food_class\" column with the \"select\" functionality.\n",
    "\n",
    "Now the McDonalds df is looking pretty good!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually assign each category to a food_class \n",
    "conditions = [(mcd_transformed['category'] == 'Breakfast') | (mcd_transformed['category'] == 'Beef & Pork') \\\n",
    "                  | (mcd_transformed['category'] == 'Chicken & Fish') | (mcd_transformed['category'] == 'Salads') \\\n",
    "                  | (mcd_transformed['category'] == 'Snacks & Sides'),\n",
    "              (mcd_transformed['category'] == 'Beverages') | (mcd_transformed['category'] == 'Smoothies & Shakes') \\\n",
    "                  | (mcd_transformed['category'] == 'Coffee & Tea'),\n",
    "              (mcd_transformed['category'] == 'Desserts'), \n",
    "             ]\n",
    "\n",
    "values = [3, 2, 1]\n",
    "\n",
    "mcd_transformed['food_class'] = np.select(conditions, values)\n",
    "\n",
    "mcd_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Data Frame Transformation: bk_mcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_mcd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at this data frame with the jupyter notebook, we see something interesting compared to the first two examples. This data frame is not just for a single resturant, but for both McDonald's and Burger King combined!\n",
    "\n",
    "We won't deal with that yet but it will force a new bit of code soon.\n",
    "\n",
    "For now we grab our columns and rename them just as we had done in the previous two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "bk_mcd_cols = [\"Chain\", \"Type\", \"Item\", \"Saturated Fat (g)\", \"Calories\"]\n",
    "bk_mcd_transformed= bk_mcd_df[bk_mcd_cols].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "bk_mcd_transformed = bk_mcd_transformed.rename(columns={\"Type\": \"category\",\n",
    "                                                    \"Item\": \"item\",\n",
    "                                                    \"Saturated Fat (g)\": \"saturated_fat\",\n",
    "                                                    \"Calories\": \"calories\"})\n",
    "\n",
    "bk_mcd_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we take a look at the \"category\" column so that we can properly classify the data into one of our three \"food_class\" numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find full list of categories\n",
    "bk_mcd_transformed['category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a conditions variable is once again created. Values are again assigned using numpy \"select\" functionality, and our combo-resturant data frame is looking just like the other two before it...\n",
    "\n",
    "but that is not what we want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually assign each category to a food_class \n",
    "conditions = [(bk_mcd_transformed['category'] == 'Whopper Sandwiches') | (bk_mcd_transformed['category'] == 'Flame Broiled Burgers') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'Chicken & More') | (bk_mcd_transformed['category'] == 'Salads & Sides') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'King Jr Meals - Entrees') | (bk_mcd_transformed['category'] == 'King Jr Meals - Sides') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'Breakfast') | (bk_mcd_transformed['category'] == 'Additional Options') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'Sandwiches') | (bk_mcd_transformed['category'] == 'French Fries') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'Chicken & Sauce') | (bk_mcd_transformed['category'] == 'Salads') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'Salad Dressings'),\n",
    "              (bk_mcd_transformed['category'] == 'Beverages') | (bk_mcd_transformed['category'] == 'McCafe Coffees') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'King Jr Meals - Beverages') | (bk_mcd_transformed['category'] == 'Shakes/Smoothies') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'Soft Drinks') | (bk_mcd_transformed['category'] == 'Hot Coffees') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'Iced Coffees') | (bk_mcd_transformed['category'] == 'Frappes') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'McCafe Coffees - Nonfat Milk') | (bk_mcd_transformed['category'] == 'McCafe Coffees - Whole Milk') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'McCafe Frappes') | (bk_mcd_transformed['category'] == 'McCafe Smoothies'),\n",
    "              (bk_mcd_transformed['category'] == 'Desserts') | (bk_mcd_transformed['category'] =='King Jr Meals - Desserts') \\\n",
    "                  | (bk_mcd_transformed['category'] == 'Desserts/Shakes') | (bk_mcd_transformed['category'] =='King Jr Meals - Desserts'), \n",
    "             ]\n",
    "\n",
    "values = [3, 2, 1]\n",
    "\n",
    "bk_mcd_transformed['food_class'] = np.select(conditions, values)\n",
    "\n",
    "bk_mcd_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want each resturant to eventually be loaded into its' own table in pgAdmin, we need to seperate the Burger King and McDonald data into to seperate data frames here.\n",
    "\n",
    "First we need to remove the \"space\" from the Burger King entry, and adjust the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bad data (namely the  ' -   ' values found in the original csv)\n",
    "bk_mcd_transformed = bk_mcd_transformed[bk_mcd_transformed['saturated_fat'] != ' -   ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert , decimal place to . and set to float64 datatype\n",
    "bk_mcd_transformed['saturated_fat'] = bk_mcd_transformed['saturated_fat'].str.replace(',', '.')\n",
    "bk_mcd_transformed['saturated_fat'] = bk_mcd_transformed['saturated_fat'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data frame is ready to be split based on what information is present in the \"Chain\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split bk and mcd into seperate dataframes\n",
    "bk_transformed =  bk_mcd_transformed.loc[bk_mcd_transformed['Chain'] == 'Burger King']\n",
    "mcd_2_join_transformed =  bk_mcd_transformed.loc[bk_mcd_transformed['Chain'] == 'Mc Donalds']\n",
    "mcd_2_join_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this leaves us now with two seperate McDonald's data frames, one from each csv. We can rectify this by doing a right join of each of these df's so that any new information from our newly created McDonald's df is added and any repeat information is skipped.\n",
    "\n",
    "This will eventually leave us with just one McDonald's df and one Burger King df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_transformed_combined = mcd_transformed.merge(mcd_2_join_transformed, how = \"right\")\n",
    "mcd_transformed_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is left to do is to remove the now uneeded \"Chain\" column in each of these data frames and set their index to \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Chain' column from the dataframes\n",
    "mcd_transformed_combined = mcd_transformed_combined.drop(columns=['Chain'])\n",
    "bk_transformed = bk_transformed.drop(columns=['Chain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_transformed_combined[\"id\"] = mcd_transformed_combined.index\n",
    "mcd_transformed_combined.set_index(\"id\", inplace=True)\n",
    "mcd_transformed_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_transformed[\"id\"] = bk_transformed.index\n",
    "bk_transformed.set_index(\"id\", inplace=True)\n",
    "bk_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Transform: starbucks_food_df and starbucks_drink_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing that we haven't already seen before is done in either of the starbucks df's.\n",
    "\n",
    "The food based data frame is loaded first. After viewing it's contents, the columns are selected, copied and renamed accordingly using all of the same method's as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starbucks_food_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "starbs_food_cols = [\"Category\", \"Name\", \"Calories\", \"Saturated Fat(g)\"]\n",
    "starbs_food_transformed= starbucks_food_df[starbs_food_cols].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "starbs_food_transformed = starbs_food_transformed.rename(columns={\"Category\": \"category\",\n",
    "                                                                \"Name\": \"item\",\n",
    "                                                                \"Saturated Fat(g)\": \"saturated_fat\",\n",
    "                                                                \"Calories\": \"calories\"\n",
    "                                                                })\n",
    "\n",
    "# Show transformed db\n",
    "starbs_food_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was our favorite data frame because all of the items were in the 3 (food) base \"food_class\" so all that had to be done was to create that new column and set it equal to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column for class designator\n",
    "# Set column value equal to \"food_class number 3\" designating food for all\n",
    "starbs_food_transformed[\"food_class\"] = 3\n",
    "\n",
    "starbs_food_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were wrong...\n",
    "\n",
    "The \"category\" column here wasn't as revealing as our previous data frames, so instead we looked at the item column and all of the unique items available. This revealed which of the items should acutally be updated to be in the 1 (dessert) category.\n",
    "\n",
    "The update was done using the conditions list and numpy functionality again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starbs_food_transformed[\"item\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update individual item to dessert class if needed\n",
    "# Assign each category to a food_class manually\n",
    "conditions = [(starbs_food_transformed[\"item\"] == \"Birthday Cake Pop\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Blueberry Oat Cake\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Chocolate Cake Pop\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Chocolate Chip Cookie\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Chocolate Chip Cookie Dough Cake Pop\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Classic Coffee Cake\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Confetti Sugar Cookie\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Double Chocolate Chunk Brownie\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Frosted Doughnut Cake Pop\")|\n",
    "              (starbs_food_transformed[\"item\"] == \"Gluten-Free Marshmallow Dream Bar\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Iced Lemon Loaf Cake\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Old-Fashioned Glazed Doughnut\") |\n",
    "              (starbs_food_transformed[\"item\"] == \"Strawberry Cake Pop\")\n",
    "             ]\n",
    "\n",
    "# This is the value for a dessert\n",
    "values = [1]\n",
    "\n",
    "starbs_food_transformed['food_class'] = np.select(conditions, values)\n",
    "        \n",
    "# Show transformed db    \n",
    "starbs_food_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we did replaced anything that was changed to a zero back to a 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all 0 values back to 3 for food_class\n",
    "starbs_food_transformed[\"food_class\"].replace(0, 3, inplace = True)\n",
    "starbs_food_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same steps are followed again for the Starbucks \"drinks\" data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_drink_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "starbs_drink_cols = [\"Category\", \"Name\", \"Calories\", \"Saturated fat(g)\"]\n",
    "starbs_drink_transformed= starbucks_drink_df[starbs_drink_cols].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "starbs_drink_transformed = starbs_drink_transformed.rename(columns={\"Category\": \"category\",\n",
    "                                                                    \"Name\": \"item\",\n",
    "                                                                    \"Saturated fat(g)\": \"saturated_fat\",\n",
    "                                                                    \"Calories\": \"calories\"\n",
    "                                                                    })\n",
    "\n",
    "# Show transformed db\n",
    "starbs_drink_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame really really was our favorite because this time all of the \"food_class\" was actually drink and could just recieve a blanked \"2\" for the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column for class designator\n",
    "# Set column value equal to \"food_class number 2\" designating drink for all\n",
    "starbs_drink_transformed[\"food_class\"] = 2\n",
    "\n",
    "starbs_drink_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all of the different category listings\n",
    "#starbs_drink_transformed[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we could have one table for Starbucks, we combined these two data frames using an outer join. Because the columns matched perfectly, the outer join worked perfectly and we now had our Starbucks menu data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the dataframes to get a starbucks food and drink df\n",
    "starbs_menu_df = starbs_food_transformed.merge(starbs_drink_transformed, how = \"outer\")\n",
    "starbs_menu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column \"saturated_fat\" was moved infront of the column \"calories\" here so that it would be congruent with our other data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust so saturated_fat column is before calories\n",
    "mid = starbs_menu_df[\"saturated_fat\"]\n",
    "starbs_menu_df.drop(labels=[\"saturated_fat\"], axis = 1, inplace = True)\n",
    "starbs_menu_df.insert(2, \"saturated_fat\", mid)\n",
    "starbs_menu_df[\"id\"] = starbs_menu_df.index\n",
    "starbs_menu_df.set_index(\"id\", inplace=True)\n",
    "starbs_menu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L - Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we will be connecting to the database that was made in pgAdmin before this jupyter notebook was run.\n",
    "\n",
    "Remeber: before running the following cells, you will have needed to run the \"ERD.sql\" file in pgAdmin and created a \"config.py\" file with your username and password. Please be sure to follow our provided readme closely before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Username and Password for pgAdmin\n",
    "# Also update Database Name to match what you created at the start\n",
    "connection_string = f\"{username}:{password}@localhost:5432/FastFood_db\"\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure everything was set up and the config.py file is running correctly, see if you get the correct names to return back from the engine that is connected to your pgAdmin database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm tables\n",
    "# You should see [\"McDonalds\", \"Burger_King\", \"Starbucks\", \"Subway\", \"Food_Classes\"]\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrames into database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pandas function \".to_sql\" we can load the data frames we transformed in this jupyter notebook to our connected engine. If all of the steps have been followed up to this point, after running the next four cells, you can switch over to pgAdmin to query your new fully populated tables!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use \"to_sql\" function to load all transformed dfs' data into postgres\n",
    "\n",
    "# Starbucks\n",
    "starbs_menu_df.to_sql(name='Starbucks', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subway\n",
    "subway_transformed.to_sql(name='Subway', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McDonalds\n",
    "mcd_transformed_combined.to_sql(name='McDonalds', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burger King\n",
    "bk_transformed.to_sql(name='Burger_King', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
